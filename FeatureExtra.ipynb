{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  ...  oldpeak  slope  ca        thal  target\n",
       "0   63    1   1       145   233  ...      2.3      3   0       fixed       0\n",
       "1   67    1   4       160   286  ...      1.5      2   3      normal       1\n",
       "2   67    1   4       120   229  ...      2.6      2   2  reversible       0\n",
       "3   37    1   3       130   250  ...      3.5      3   0      normal       0\n",
       "4   41    0   2       130   204  ...      1.4      1   0      normal       0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 49 61\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tf.data的函数完成特征构造\n",
    "\n",
    "# 一种从pd dataframe 创建tf.data数据集的实用程序方法\n",
    "def df_2_dataset(dataframe, label_name='label', shuffle=True, batch_size = 32):\n",
    "    df = dataframe.copy()\n",
    "    labels = df.pop(label_name)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds.shuffle(buffer_size = len(dataframe))\n",
    "    \n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
      "A batch of ages: tf.Tensor([41 62 37 51 63], shape=(5,), dtype=int32)\n",
      "A batch of targets: tf.Tensor([0 1 0 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 演示效果\n",
    "train_ds = df_2_dataset(train, label_name='target', shuffle=False, batch_size = 5)\n",
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "    print('A batch of ages:', feature_batch['age'])\n",
    "    print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于演示的数据：\n",
    "example_batch = next(iter(train_ds))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([41, 62, 37, 51, 63], dtype=int32)>,\n",
       " 'sex': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 0, 1, 1, 0], dtype=int32)>,\n",
       " 'cp': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([3, 3, 3, 3, 3], dtype=int32)>,\n",
       " 'trestbps': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([112, 130, 130, 110, 135], dtype=int32)>,\n",
       " 'chol': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([250, 263, 250, 175, 252], dtype=int32)>,\n",
       " 'fbs': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'restecg': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 2], dtype=int32)>,\n",
       " 'thalach': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([179,  97, 187, 123, 172], dtype=int32)>,\n",
       " 'exang': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'oldpeak': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([0. , 1.2, 3.5, 0.6, 0. ])>,\n",
       " 'slope': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 2, 3, 1, 1], dtype=int32)>,\n",
       " 'ca': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 0], dtype=int32)>,\n",
       " 'thal': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'normal', b'reversible', b'normal', b'normal', b'normal'],\n",
       "       dtype=object)>,\n",
       " 'target': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 0], dtype=int32)>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于创建一个特征列，并转换一批次的数据的实用方法\n",
    "def batch2features(feature_name):\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_name)\n",
    "    features = feature_layer(example_batch).numpy()\n",
    "    print(features)\n",
    "    print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 21:56:58.855246 140736001074112 base_layer.py:1790] Layer dense_features_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41.]\n",
      " [62.]\n",
      " [37.]\n",
      " [51.]\n",
      " [63.]]\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "# 数值类\n",
    "\n",
    "# 使用tf的feature_column做数值转换\n",
    "batch2features(feature_column.numeric_column(\"age\"))\n",
    "feature_age = 'f_age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 21:56:59.901951 140736001074112 base_layer.py:1790] Layer dense_features_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "(5, 11)\n"
     ]
    }
   ],
   "source": [
    "# 分桶类\n",
    "age = feature_column.numeric_column('age')\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65]) # 首位各一个\n",
    "batch2features(age_buckets)\n",
    "feature_age_buk = ['f_age_buk_' + str(i) for i in range(11)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fixed', 'normal', 'reversible', '1', '2'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类列\n",
    "df['thal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 21:57:02.931308 140736001074112 base_layer.py:1790] Layer dense_features_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "thal = feature_column.categorical_column_with_vocabulary_list(\n",
    "'thal', df['thal'].unique())\n",
    "\n",
    "batch2features(feature_column.indicator_column(thal) )\n",
    "feature_thal =  ['f_thal_' + str(i) for i in range(5)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 21:57:04.118335 140736001074112 base_layer.py:1790] Layer dense_features_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7353011   0.6216138  -0.2674025   0.350217  ]\n",
      " [ 0.01296699 -0.20875396  0.09854725 -0.7592551 ]\n",
      " [ 0.7353011   0.6216138  -0.2674025   0.350217  ]\n",
      " [ 0.7353011   0.6216138  -0.2674025   0.350217  ]\n",
      " [ 0.7353011   0.6216138  -0.2674025   0.350217  ]]\n",
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "# 嵌入列\n",
    "# 假设我们不是只有几个可能的字符串，而是每个类别有数千（或更多）值。\n",
    "batch2features(feature_column.embedding_column(thal, dimension=4))\n",
    "feature_thal_embed = ['f_thal_embed_' + str(i) for i in range(4)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 21:57:06.212072 140736001074112 base_layer.py:1790] Layer dense_features_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(5, 1000)\n"
     ]
    }
   ],
   "source": [
    "# 组合的特征列\n",
    "crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\n",
    "batch2features(feature_column.indicator_column(crossed_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "features = []\n",
    "\n",
    "# 并未实际处理，类似于tf早期版本，先定义网络\n",
    "# 数值列\n",
    "for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:\n",
    "    features.append(feature_column.numeric_column(header))\n",
    "    feature_names.append('f_' + header)\n",
    "\n",
    "# 分桶列\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "features.append(age_buckets)\n",
    "feature_names.append('f_' + 'age_buckets')\n",
    "\n",
    "# 分类列\n",
    "thal = feature_column.categorical_column_with_vocabulary_list('thal', df['thal'].unique())\n",
    "thal_one_hot = feature_column.indicator_column(thal)\n",
    "features.append(thal_one_hot)\n",
    "feature_names.extend(['f_thal_' + str(i) for i in range(5)])\n",
    "\n",
    "# 嵌入列\n",
    "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
    "features.append(thal_embedding)\n",
    "feature_names.extend(['f_thal_embed_' + str(i) for i in range(8)])\n",
    "\n",
    "# 组合列\n",
    "crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\n",
    "crossed_feature = feature_column.indicator_column(crossed_feature)\n",
    "features.append(crossed_feature)\n",
    "feature_names.extend(['f_cf_' + str(i) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f_age',\n",
       " 'f_trestbps',\n",
       " 'f_chol',\n",
       " 'f_thalach',\n",
       " 'f_oldpeak',\n",
       " 'f_slope',\n",
       " 'f_ca',\n",
       " 'f_age_buckets',\n",
       " 'f_thal_0',\n",
       " 'f_thal_1']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='trestbps', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='chol', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='thalach', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='oldpeak', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='slope', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='ca', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='thal', vocabulary_list=('fixed', 'normal', 'reversible', '1', '2'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='thal', vocabulary_list=('fixed', 'normal', 'reversible', '1', '2'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x131ef54a8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " IndicatorColumn(categorical_column=CrossedColumn(keys=(BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), VocabularyListCategoricalColumn(key='thal', vocabulary_list=('fixed', 'normal', 'reversible', '1', '2'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=1000, hash_key=None))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_2_dataset(train, label_name='target', batch_size=batch_size)\n",
    "val_ds = df_2_dataset(val, label_name='target', batch_size=batch_size)\n",
    "test_ds = df_2_dataset(test, label_name='target', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.DenseFeatures(features))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics = ['accuracy'],\n",
    "                 run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 7 steps, validate for 2 steps\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 1.1109 - accuracy: 0.6062 - val_loss: 1.4839 - val_accuracy: 0.3061\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 1.6927 - accuracy: 0.5130 - val_loss: 0.7285 - val_accuracy: 0.7959\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.7607 - accuracy: 0.6166 - val_loss: 0.7330 - val_accuracy: 0.5918\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.7814 - accuracy: 0.6943 - val_loss: 0.4420 - val_accuracy: 0.8163\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 52ms/step - loss: 0.8162 - accuracy: 0.6477 - val_loss: 0.4197 - val_accuracy: 0.8367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134d5bb00>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_ds, validation_data=val_ds, epochs =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5019 - accuracy: 0.7869\n",
      "Accuracy 0.78688526\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
